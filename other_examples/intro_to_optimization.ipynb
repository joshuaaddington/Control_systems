{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Optimization (BYU ME 431 / ECE 483)\n",
    "\n",
    "It is important to understand that this intro is not meant as an exhaustive resource to learn about optimization. In fact, it is really only meant to help us understand the very basic ideas at a high level. The motivation for this to then better understand more about the feedback control topics of linear quadratic regulators (LQR) and model predictive control (MPC) at an undergraduate level. \n",
    "\n",
    "Let's start by looking at the definition of a basic cost function and its plot to understand what we mean by \"minimizing\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def objective(x): \n",
    "    f = x**2\n",
    "    return f\n",
    "\n",
    "\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "y = objective(x)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, label=r'$f(x) = x^2$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cost function $f(x)$ and the free variable $x$ could represent anything from the monetary cost of a component we are designing, to energy consumption of a specific circuit, to error in a feedback controller. In all cases, we have a variable we can change ($x$) and we want to find the value for $x$ that makes our cost the smallest value possible. In the picture above, this would happen when $x=0$ and $f(x)=0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Minimum\n",
    "\n",
    "Given the plot above, how can we find the minimum, or the value for $x$ where $f(x)$ is the smallest in an algorithmic way? In this case, it is quite simple and we can define it by inspection (as $x=0$). However, this is a great opportunity to understand a little about how optimization works. If we assume that we do not know the solution, but instead we only have access to our function, and our first guess for the optimimum was $x=8$, how could we proceed? The following shows a very simple method for using the derivative of our cost function (or gradient in the case of multi-variable problems) to decrease the cost in an interative fashion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_of_objective(x): \n",
    "    f_prime = 2*x\n",
    "    return f_prime\n",
    "\n",
    "# initial guess for x, and cost value for f(x) \n",
    "x_0 = 8.0\n",
    "y_0 = objective(x_0)\n",
    "\n",
    "# we want to reduce our current cost of f(4), so we try to move x_0 in a \"good direction,\" one that \n",
    "# will decrease the cost. \n",
    "x_1 = x_0 - 0.1*deriv_of_objective(x_0)\n",
    "\n",
    "# why did we negate the derivative? and why did we scale it by 0.1? \n",
    "# let's evaluate our function at the new point, x_1:\n",
    "y_1 = objective(x_1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, label=r'$f(x) = x^2$')\n",
    "plt.plot(x_0, y_0, 'ro', label=r'$f(8) = 64$')\n",
    "plt.plot(x_1, y_1, 'go', label=r'$f(6.4) = 40.96$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did taking a step (or modifying our guess for $x_0$) by using the negative of the derivative of the cost function (i.e. $-\\frac{\\partial{f}}{\\partial{x}}$) work? Did it decrease the cost? \n",
    "\n",
    "Because this function ($f(x) = x^2$) is so simple, we may be wondering why we need a method like this at all. And in truth, we could just randomly sample values for $x$ from our function $f(x)$ until we found the minimum or something close to it. In fact, there are many sampling-based methods that can be appropriate depending on the problem form and complexity. But these methods will almost always be slower than using a method related to the derivative as we've shown above. In this case we don't know how big of a step in the direction of $-\\frac{\\partial{f}}{\\partial{x}}$ that we should take, and using $0.1$ was fairly arbitrary. There are actually methods using second derivatives (or the Hessian) that will show us what step (or approximate step) size to take. This works especially well if the cost function is quadratic or if it can be approximated that way. \n",
    "\n",
    "Regardless, even if we are not clever about the step size, this method can work to cause us to converge to the minimum if we just repeat the process iteratively as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cur = y_1\n",
    "x_cur = x_1\n",
    "\n",
    "# storing intermediate values for plotting\n",
    "x_opt_process = [x_1]\n",
    "y_opt_process = [y_1]\n",
    "\n",
    "# this condition only works because I know that the function is convex and has a minimum at 0.\n",
    "while y_cur > 0.001: \n",
    "    x_cur = x_cur - 0.1*deriv_of_objective(x_cur)\n",
    "    y_cur = objective(x_cur)\n",
    "\n",
    "    x_opt_process.append(x_cur)\n",
    "    y_opt_process.append(y_cur)\n",
    "\n",
    "# let's plot the optimization process\n",
    "plt.figure()\n",
    "plt.plot(x, y, label=r'$f(x) = x^2$')\n",
    "plt.plot(x_0, y_0, 'ro', label=r'$f(x_0)$')\n",
    "plt.plot(x_opt_process, y_opt_process, 'go', label='Optimization Steps')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we may wonder if this works for other functions or starting positions. Let's try it in the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x): \n",
    "    f = (x-4)**2 + 2\n",
    "    return f\n",
    "\n",
    "def deriv_of_objective(x): \n",
    "    f_prime = 2*(x-4)\n",
    "    return f_prime\n",
    "\n",
    "# variables to plot the new cost function\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "y = objective(x)\n",
    "\n",
    "# initial guess for x, and cost value for f(x)\n",
    "x_0 = -7.0\n",
    "y_0 = objective(x_0)\n",
    "\n",
    "y_cur = y_0\n",
    "x_cur = x_0\n",
    "\n",
    "# let's make a function to peform this iterative optimization process\n",
    "def optimize(x_cur, y_cur, objective, deriv_of_test_function):\n",
    "    x_opt_process = []\n",
    "    y_opt_process = []\n",
    "\n",
    "    # we need a new stopping condition since we no longer know the minimum exactly. \n",
    "    # we can just check to see if y_cur is decreasing slowly to see if we've converged.\n",
    "    y_diff = 1000.0\n",
    "    y_prev = y_cur\n",
    "    while np.abs(y_diff) > 0.01:\n",
    "        x_cur = x_cur - 0.1*deriv_of_test_function(x_cur)\n",
    "        y_cur = objective(x_cur)\n",
    "        \n",
    "        x_opt_process.append(x_cur)\n",
    "        y_opt_process.append(y_cur)\n",
    "\n",
    "        y_diff = y_cur - y_prev\n",
    "        y_prev = y_cur\n",
    "\n",
    "    return x_opt_process, y_opt_process\n",
    "\n",
    "x_opt_process, y_opt_process = optimize(x_cur, y_cur, objective, deriv_of_objective)\n",
    "\n",
    "# let's plot the optimization process\n",
    "plt.figure()\n",
    "plt.plot(x, y, label=r'$f(x) = x^2$')\n",
    "plt.plot(x_0, y_0, 'ro', label=r'$f(x_0)$')\n",
    "plt.plot(x_opt_process, y_opt_process, 'go', label='Optimization Steps')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it works! At least for simple functions. Let's try it for one more function that is not quadratic and see the problem of \"local minima\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x):\n",
    "    f = x**3 - 3*x + 2\n",
    "    return f\n",
    "\n",
    "def deriv_of_objective(x):\n",
    "    f_prime = 3*x**2 - 3\n",
    "    return f_prime\n",
    "\n",
    "x = np.linspace(-3, 3, 1000)\n",
    "y = objective(x)\n",
    "\n",
    "x_0 = -.5\n",
    "y_0 = objective(x_0)\n",
    "\n",
    "y_cur = y_0\n",
    "x_cur = x_0\n",
    "\n",
    "x_opt_process, y_opt_process = optimize(x_cur, y_cur, objective, deriv_of_objective)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, label=r'$f(x) = x^3 - 3x + 2$')\n",
    "plt.plot(x_0, y_0, 'ro', label=r'$f(x_0)$')\n",
    "plt.plot(x_opt_process, y_opt_process, 'go', label='Optimization Steps')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this the minimum? By inspection, what would the minimum be? in a practical engineering application, what would stop us from moving $x$ to $-\\infty$? To summarize, our current method to optimize did NOT find the minimum. And in most problems we would have a limit or constraint on $x$ that would cause our minimum to be at the constraint on the left side of this plot instead of going to $-\\infty$. \n",
    "\n",
    "Much of the complexity of optimization comes as we look in more detail at how to approximate cost functions to look quadratic, or how to determine the right step size. However, the basic principles of what we have seen here still apply. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constraints\n",
    "\n",
    "What about optimimizations where we cannot change $x$ to be whatever value we want? Controls problems are a good example of this, where our state variable $x$ may have physical limits, or the input $u$ may also saturate or be limited. To handle constraints, we have to introduce additional principles that are beyond the scope of this lesson. But we can use existing libraries and tools to visualize the effects of these constraints. \n",
    "\n",
    "Let's start with the same example as before but if we require $x\\geq 2$, how does that change the problem? By inspection, can you still determine the minimum? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x): \n",
    "    f = x**2\n",
    "    return f\n",
    "\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "y = objective(x)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, label=r'$f(x) = x^2$')\n",
    "plt.axvline(2, color='purple', linestyle='--', label=f'Constraint: x >= 2')\n",
    "plt.fill_between(x, -np.ones(len(x))*5, np.ones(len(x))*100, where=(x >= 2), alpha=0.3, color='gray', label='Feasible Region')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if instead of an inequality constraint, it is an equality constraint? Such as $x=2$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x): \n",
    "    f = x**2\n",
    "    return f\n",
    "\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "y = objective(x)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, label=r'$f(x) = x^2$')\n",
    "plt.axvline(2, color='purple', linestyle='--', label=f'Constraint: x = 2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem the equality constraint only overlaps with our cost function in one place. So that is the only possible solution. Even if there is only one possible solution, optimization gives us an efficient way to find it!\n",
    "\n",
    "Let's look at one example were we can use existing optimization libraries in scipy to solve a constrained optimization and see how the constraint affects our result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define an objective function (simple quadratic)\n",
    "def objective(x):\n",
    "    return (x**2)\n",
    "\n",
    "# Define a constraint function (e.g., x >= a)\n",
    "def constraint(x, a):\n",
    "    return x - a\n",
    "\n",
    "# Function to plot unconstrained and constrained optimization, input is the constraint value\n",
    "def plot_optimization(x_lim):\n",
    "    x = np.linspace(-6, 6, 100)\n",
    "    y = objective(x)\n",
    "    x_0 = 8.0 \n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    # Plot objective function\n",
    "    plt.plot(x, y, label=\"Objective function\", lw=2)\n",
    "\n",
    "    # Unconstrained minimum\n",
    "    x_unconstrained = minimize(objective, x0=x_0).x[0]\n",
    "    plt.scatter(x_unconstrained, objective(x_unconstrained), color='red', label='Unconstrained minimum')\n",
    "\n",
    "    # Constrained minimum\n",
    "    cons = ({'type': 'ineq', 'fun': lambda x: constraint(x, x_lim)})\n",
    "    x_constrained = minimize(objective, x0=x_0, constraints=cons).x[0]\n",
    "    plt.scatter(x_constrained, objective(x_constrained), color='green', label='Constrained minimum')\n",
    "\n",
    "    # Plot constraint line\n",
    "    plt.axvline(x_lim, color='purple', linestyle='--', label=f'Constraint x â‰¥ {x_lim}')\n",
    "\n",
    "    plt.title(\"Unconstrained vs Constrained Optimization\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"Objective\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "x_lim = 1.0\n",
    "plot_optimization(x_lim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-variable Quadratic Costs\n",
    "\n",
    "SO much of what makes optimization more complex than what we have shown are functions that have local minima (as shown above) or optimizations that have non-convex functions. However, we are lucky. For an introduction to optimal control in this class, we will mostly assume that we can write our cost function as quadratic in states ($x$) and inputs ($u$). This would take the following form:\n",
    "\n",
    "$$ \\begin{equation}\n",
    "J = \\int_{0}^{T} \\left( \\mathbf{x}(t)^{\\top} \\mathbf{Q} \\mathbf{x}(t) + \\mathbf{u}(t)^{\\top} \\mathbf{R} \\mathbf{u}(t) \\right) dt\n",
    "\\end{equation}$$\n",
    "\n",
    "To solve this optimization is not easy, and we need to include our dynamics as an equality constraint (since we cannot change $x$ and $u$ independent from each other), and we do not yet know the forms for $Q$ and $R$, but hopefully you can see how we are essentially squaring $x$ and squaring $u$. The integral may be a little confusing, but you can think if it as summing the values for our states and inputs at every time step across the limits of integration. \n",
    "\n",
    "We will come back to this in our next lesson, but for now, let us look at just one more example of a two-variable quadratic function that includes an equality constraint. \n",
    "\n",
    "If we return to our cruise control example, and instead of looking at an integral or a time horizon, we just look at a single time step, we can formulate the following optimization problem: \n",
    "\n",
    "$$ \\min_{v_{i+1},F_i} J = [v_{i+1}]^T Q [v_{i+1}] + [F_i]^T R [F_i] $$\n",
    "$$ \\textrm{subject to:} \\quad v_{i+1} =  v_i + \\dot{v}_i \\Delta t = v_i + (-\\frac{b}{m}v_i + \\frac{F_i}{m})\\Delta t$$\n",
    "\n",
    "This may seem a little odd, but we are saying that we have a cost that is a function of our car velocity $v$ at the next time step ($i+1$) and of our applied force $F$ at the current time step ($i$). In addition, our velocity at the next time step ($i+1$) is an equality constraint that is a function of our current velocity (at time step $i$) and chosen force ($F_i$). This form of cost is quadratic for a single time step (and even for multiple time steps). The goal of this optimization is to drive the value of our cost $J$ to the lowest possible value. \n",
    "\n",
    "We can start by plotting the shape of our quadratic cost function, and finding the optimimum if we $\\textit{ignore}$ the equality constraint that describes our dynamics. The surface below represents our cost function $J$, while the red sphere shows the unconstrained minimum value for $v_{i+1}$ and $F_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Create a 3D plot of the objective function\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': '3d'}, figsize=(10, 7))\n",
    "\n",
    "# selecting a range of velocity and force values for which to calculate the objective function\n",
    "v = np.arange(-20, 20, 1)\n",
    "F = np.arange(-20, 20, 1)\n",
    "\n",
    "v, F = np.meshgrid(v, F)\n",
    "Q = 1.0\n",
    "R = 1.0\n",
    "\n",
    "J = v*Q*v + F*R*F\n",
    "\n",
    "surf = ax.plot_surface(v, F, J, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False,\n",
    "                       alpha=0.5,  \n",
    "                       label='objective function',\n",
    "                       zorder=0)\n",
    "ax.zaxis.set_major_formatter('{x:.02f}')\n",
    "\n",
    "# We can use the \"minimum\" function to find the unconstrained minimum\n",
    "def objective(x):\n",
    "    v = x[0]\n",
    "    F = x[1]\n",
    "    # J = v.T@Q@v + F.T@R@F\n",
    "    return v*Q*v + F*R*F\n",
    "\n",
    "# initial guess for x is a random guess\n",
    "x_0 = np.random.rand(2)*10\n",
    "x_unconstrained = minimize(objective, x0=x_0).x\n",
    "ax.scatter(x_unconstrained[0], x_unconstrained[1], \n",
    "           objective(x_unconstrained), color='red', \n",
    "           label='unconstrained minimum', marker='o', \n",
    "           s=300, alpha=1, zorder=10)\n",
    "\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.xlabel('velocity')\n",
    "plt.ylabel('force')\n",
    "plt.title('Objective Function') \n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of varying Q and R \n",
    "\n",
    "One thing we might want to explore is to better understand the role of $Q$ and $R$. In this example, these matrices contain a single scalar, but it is the relative values between $Q$ and $R$ that will change the shape of our quadratic cost function. In plot above $Q=R=1$, but let's set $Q=1$ and $R=0.2$. Notice how the overall unconstrained solution did not change, but the shape is now elongated in the direction of force ($F$). Another way of thinking about this is that because $Q$ is so much higher than $R$, we will reduce our cost more by changing $v$ than by changing $F. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 1.0\n",
    "R = 0.2\n",
    "\n",
    "J = v*Q*v + F*R*F\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': '3d'}, figsize=(10, 7))\n",
    "surf = ax.plot_surface(v, F, J, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False,\n",
    "                       alpha=0.5,  \n",
    "                       label='objective function',\n",
    "                       zorder=0)\n",
    "ax.zaxis.set_major_formatter('{x:.02f}')\n",
    "\n",
    "# Finding the unconstrained minimum (i.e. not using our equality constraint)\n",
    "def objective(x):\n",
    "    v = x[0]\n",
    "    F = x[1]\n",
    "    # J = v.T@Q@v + F.T@R@F\n",
    "    return v*Q*v + F*R*F\n",
    "\n",
    "x_0 = np.random.rand(2)*10\n",
    "x_unconstrained = minimize(objective, x0=x_0).x\n",
    "ax.scatter(x_unconstrained[0], x_unconstrained[1], objective(x_unconstrained), \n",
    "           color='red', label='unconstrained minimum', marker='o', s=300, \n",
    "           alpha=1, zorder=10)\n",
    "\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.xlabel('velocity')\n",
    "plt.ylabel('force')\n",
    "plt.title('Objective Function') \n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including the Dynamics Constraint\n",
    "\n",
    "The problem with this solution is that it is not physically meaningful. In the example above, we seeded or started our optimization with random values for $v_{i+1}$ and $F_i$ and let it optimize with no constraint. However, in a controls problem, we do not get to set the initial velocity $v_i$, and our velocity in the cost function (which is v at the next time step $v_{i+1}$) depends on both $v_i$ and $F_i$ since we cannot change velocity instantanously. To account for this constraint, we can substitute the constraint back into the cost function for $v_{i+1}$ (essentially removing our equality constraint and forcing our cost to only be a function of $F_i$ now, since $v_i$ is a given): \n",
    "\n",
    "$$\\min_{F_i} J = \\left[(1-\\frac{b}{m}\\Delta t )v_i + \\frac{F_i}{m}\\Delta t \\right]^T Q \\left[(1-\\frac{b}{m}\\Delta t )v_i + \\frac{F_i}{m}\\Delta t \\right] + [F_i]^T R [F_i] $$\n",
    "\n",
    "\n",
    "This process is not something we will need to do in this class. However, it allows us to now to now see the effect of including the equality constraint that describes our dynamics. This problem is still quadratic, but has some constant terms related to $v_i$ now. This shifts where the functions is centered, but the solution is still at the bottom of the \"bowl\". See below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dynamics constraint: \n",
    "# these parameters are not realistic to a car, but the scaling makes plotting\n",
    "# and understanding the trade-off in costs easier. \n",
    "m = 1\n",
    "b = 0.1\n",
    "def f_dyn(v, F): \n",
    "    # f_dyn = -b/m*v + F/m \n",
    "    return -b/m*v + F/m\n",
    "\n",
    "delta_t = 0.01\n",
    "Q = 1.0\n",
    "R = 1.0\n",
    "def objective_constrained(F): \n",
    "    v = 8.0\n",
    "    J = (v+f_dyn(v, F)*delta_t)**2*Q + (F)**2 * R\n",
    "    return J \n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': '3d'}, figsize=(10, 7))\n",
    "\n",
    "# this is our initial velocity, and a range of forces to see the effect on the cost function \"J\"\n",
    "v_i = 8.0\n",
    "F = np.arange(-10, 10, 1)\n",
    "\n",
    "v_constrained = np.arange(v_i-1, v_i+2, 1)\n",
    "v_constrained, F_constrained = np.meshgrid(v_constrained, F)\n",
    "J_constrained = objective_constrained(F_constrained)\n",
    "\n",
    "surf = ax.plot_surface(v_constrained, F_constrained, J_constrained, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False,\n",
    "                       alpha = 0.5, \n",
    "                       label = r'objective function for $v_i=8$',\n",
    "                       zorder=0)\n",
    "ax.zaxis.set_major_formatter('{x:.02f}')\n",
    "\n",
    "# Finding the constrained minimum\n",
    "x_constrained = minimize(objective_constrained, x0=10).x \n",
    "ax.scatter(v_i, x_constrained, objective_constrained(x_constrained), \n",
    "           color='green', label='constrained minimum', \n",
    "           marker = 'o', s=300, \n",
    "           alpha=1, zorder=10)\n",
    "\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.xlabel('velocity')\n",
    "plt.ylabel('force')\n",
    "plt.title('Objective Function') \n",
    "plt.xlim(v_i - 10, v_i + 10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, this tells us that if we care equally about velocity, and force, the best thing to do is to apply zero force ($F_i = 0$). However, this is likely not true about our problem. We mostly will care more about velocity and want to use force to drive velocity to a zero (or another desired value). \n",
    "\n",
    "To understand this better, we'll next just plot two more examples, where we are looking at the cost for a given $v_i=8$ (assuming this is our initial condition when we start our \"controller\") and using two different sets of $Q$ and $R$ as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t = 0.01 # time step for integration\n",
    "\n",
    "# initial velocity at time step \"i\"\n",
    "v_i = 8.0\n",
    "\n",
    "def objective_constrained_set1(F): \n",
    "    Q = 1.0\n",
    "    R = 0.05\n",
    "\n",
    "    v = v_i\n",
    "    J = (v+f_dyn(v, F)*delta_t)**2*Q + (F)**2 * R\n",
    "    return J \n",
    "\n",
    "def objective_constrained_set2(F): \n",
    "    Q = 0.05\n",
    "    R = 1.0\n",
    "\n",
    "    v = v_i\n",
    "    J = (v+f_dyn(v, F)*delta_t)**2*Q + (F)**2 * R\n",
    "    return J \n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': '3d'}, figsize=(10, 7))\n",
    "\n",
    "# make a range of forces to see the effect on the cost function \"J\" \n",
    "# for two different sets of Q and R\n",
    "F = np.arange(-10, 10, 1)\n",
    "v_constrained = np.arange(v_i-1, v_i+2, 1)\n",
    "v_constrained, F_constrained = np.meshgrid(v_constrained, F)\n",
    "J_constrained1 = objective_constrained_set1(F_constrained)\n",
    "J_constrained2 = objective_constrained_set2(F_constrained)\n",
    "\n",
    "surf = ax.plot_surface(v_constrained, F_constrained, J_constrained1, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False,\n",
    "                       alpha = 0.5, \n",
    "                       label = r'$Q=1.0$ and $R=0.05$',\n",
    "                       zorder=0)\n",
    "surf2 = ax.plot_surface(v_constrained, F_constrained, J_constrained2, cmap=cm.jet,\n",
    "                       linewidth=0, antialiased=False,\n",
    "                       alpha = 0.5, \n",
    "                       label = r'$Q=0.05$ and $R=1.0$',\n",
    "                       zorder=0)\n",
    "\n",
    "ax.zaxis.set_major_formatter('{x:.02f}')\n",
    "\n",
    "\n",
    "x_constrained1 = minimize(objective_constrained_set1, x0=0).x #minimize(objective, x0=x_0, constraints=cons).x[0]\n",
    "ax.scatter(v_i, x_constrained1, objective_constrained_set1(x_constrained1), \n",
    "           color='red', label='constrained minimum for Q,R set 1', \n",
    "           marker = 'o', s=300, \n",
    "           alpha=1, zorder=10)\n",
    "\n",
    "x_constrained2 = minimize(objective_constrained_set2, x0=0).x #minimize(objective, x0=x_0, constraints=cons).x[0]\n",
    "ax.scatter(v_i, x_constrained2, objective_constrained_set2(x_constrained2), \n",
    "           color='blue', label='constrained minimum for Q,R set 2', \n",
    "           marker = 'o', s=300, \n",
    "           alpha=1, zorder=10)\n",
    "\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.xlabel('velocity')\n",
    "plt.ylabel('force')\n",
    "plt.title('Objective Function') \n",
    "plt.xlim(v_i -10, v_i + 10)\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the values for $Q$ and $R$ above to better understand their effects and trade-offs. In addition, you can play with $v_i$ to see how the two examples change depending on the initial condition or current velocity ($v_i$). \n",
    "\n",
    "Hopefully the above makes some sense. By including the effect of our dynamics (or the equality constraint that describes our dynamics) we can see that by applying force we can decrease velocity (and overall objective function) for one time step at a a faster rate than just letting the system velocity decay from the free response of the system. \n",
    "\n",
    "In next steps, we will try to understand what happens when we are optimizing over more than just one time step. This will lead us to understanding both linear quadratic regulators (LQR) and another method of optimal control called model predictive control (MPC). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
